202412 - Creating, and importantly, maintaining software templates
Maintaining software templates is often overshadowed by the excitement of creating them. Yet, the true value of these templates lies in their longevity and adaptability over time. This blog post goes beyond the basics of template creation and dives into the challenges and strategies for keeping software templates maintainable as your organization evolves.
Why read this post? If you're leveraging internal developer portals (IDPs), building microservice architectures or managing multiple repositories based on shared templates, this article will help you address key pain points, such as managing updates across projects, aligning with clean architecture principles, and ensuring consistent standards without stifling team autonomy. Whether you're a developer or part of an operations team, this post provides practical insights and a framework for balancing scalability with maintainability. This post will talk about IDPs, but it is not a requirement: in case you’re developing microservices without IDPs, you’ll still find value in this blog post.
What are software templates?
Software templates are pre-configured blueprints designed to help teams standardize and speed up the creation of software components, infrastructure, or services. While these templates are not exclusive to microservice or cloud-native development, their benefits are most apparent in that space: where maintaining numerous projects makes shared templates invaluable. For monoliths, the value is less explicit, since there are typically fewer projects to manage. I'll set that discussion aside for now, as the topic of monolith development (which often gets an undeservedly negative reputation) is planned for a future blog post and would take us too far for now.

These software templates define a consistent structure and incorporate best practices aligned with organizational policies. By abstracting common setups and configuration, they allow developers to avoid repetitive tasks, reduce errors, and focus on building features rather than boilerplate code.
For example, imagine a team tasked with creating a new microservice. Instead of manually setting up a repository, configuring CI/CD pipelines, or integrating monitoring tools, a software template can handle these tasks. A developer selects a "Java Microservice" template, provides a few details like the service name and owner, and the template generates a fully provisioned repository with pre-integrated tools such as logging, metrics, and testing and deployment pipelines. This ensures that every new microservice adheres to company standards and integrates seamlessly into the larger ecosystem.

Software templates empower organizations to deliver value faster while aiming to maintain consistency and quality across projects. Improvements to templates benefit the entire engineering organization, fostering a culture of shared best practices and balancing agility with governance.

Example software templates (mainly with Backstage and Red Hat Developer Hub in mind):
Open Liberty
Quarkus
Context
In my previous blog post, I explored the concept of internal developer portals (IDPs) and their ability to deliver software templates. These templates play a critical role in standardizing development workflows and ensuring consistency across teams. By offering built-in best practices, security measures, and compliance guidelines, templates empower developers to work independently without requiring deep operational expertise. This boosts efficiency and scalability, as services can be reliably replicated and expanded.

However, creating software templates is only part of the story. In this post, I’ll tackle a key challenge: how to ensure that templates and the projects created from them remain maintainable over time. While creating 100 microservices from a central template is straightforward, updating a shared framework across all these repositories can become a logistical nightmare if done manually.

To address this, I’ll outline a version management process inspired by clean architecture principles, which are conceptually similar to hexagonal architecture. If you're unfamiliar with these concepts, I recommend reading this initial post before proceeding.
Keeping software templates maintainable
Introduction
One of the main limitations of IDPs in their default setup is the lack of support for managing repositories created from software templates. For example, if a common library or framework needs updating across multiple repositories, the IDP doesn’t provide a built-in mechanism to handle this. This issue arises because IDPs are not inherently aware of the structure or dependencies of the code generated by their templates.

This challenge is further complicated by microservices' architecture principles, which emphasize repository independence and discourage reliance on shared code. While this independence promotes scalability and modularity, it also makes managing updates to shared components across repositories more difficult.

To solve this, I propose a solution that introduces a centralized approach to maintaining shared frameworks, while respecting the independence of individual repositories. This approach integrates seamlessly with an IDP and aligns with microservices principles, enabling effective centralized maintenance without compromising autonomy.

Next to that, you could opt for what I like to call a “pull request storm”: starting from the parent template, automated pull requests are generated and sent out to all downstream repositories whenever, for instance, the runtime version or a shared dependency needs an upgrade. Microservice developers can then review and merge these PRs at their own pace, ensuring consistency without removing autonomy.
I won’t go any deeper into this solution in this blog post, but it can be another pattern to keep in mind when thinking about the long-term sustainability of IDP-driven development.
Proposed solution: a parent framework around your application code

The solution partially relaxes the strict separation principle of microservices to introduce a centralized way of managing shared code, dependency versions, and infrastructure integrations. The aim is to simplify updates while retaining the modularity and independence of individual repositories.

For a practical demonstration of this approach, you can refer to this (parent template) GitHub repository, which includes a worked-out example of the architecture.
Repository setup: splitting code and operations
To address separation of concerns and simplify CI/CD, I recommend splitting repositories into two distinct parts:

Application Repository: Contains the source code for the application.
GitOps Repository: Holds infrastructure configuration, operations scripts, and CI/CD pipelines.

This split aligns with GitOps principles and enhances flexibility. For instance, different GitOps repositories can manage deployments across multiple environments or enable cloud migrations without altering the application repository. Developers retain ownership of the application repository, while operations teams manage the GitOps repository, ensuring clear boundaries and governance.

This approach also simplifies maintaining shared frameworks and deploying microservices built on these frameworks. Decoupling application logic from operational concerns fosters collaboration and reduces complexity.
Application code: Clean Architecture-Based Parent Project
Clean architecture principles emphasize modularity and strict dependency rules, often implemented through submodules (e.g., Gradle or Maven submodules). However, traditional implementations assume a single stakeholder: the development team (i.e., “the specialists” as I will call them through this blog post). Introducing a second stakeholder, such as a team maintaining the shared framework (i.e., “the template maintainers”), requires careful coordination.

With two stakeholders working in the same repository, a key challenge arises: how do we push changes (e.g., dependency upgrades or updates to the shared framework) without disrupting the microservice-specific code? This problem is similar to the one discussed earlier in the Repository setup: split code and operations section, where developers and operations teams shared a repository. In that case, the solution was to split the repository into two, giving each stakeholder ownership of their respective areas. However, in this scenario, splitting the repository entirely isn’t feasible. The specialists’ code depends on the parent framework code, and separating them would cause the microservice-specific code to fail to compile.

To address this, I propose splitting the code logically, maintaining separate repositories for the template maintainers’ and specialists’ codebases to maintain the principle of single responsibility: one repository per stakeholder. 
Organizing the Code Using Clean Architecture
To ensure maintainability and flexibility, the parent template follows clean architecture principles. The parent template defines a structured architecture that includes the following modules (see image below):

Core Module(s): Contains domain entities, business logic, and use cases. It is purely focused on application logic, without dependencies on external frameworks or databases.
API Module(s): Defines interfaces for external communication, including REST, GraphQL, and gRPC endpoints. This allows the implementation to be decoupled from the communication protocol.
Data Providers Module(s): Implements the data access logic, such as repository interfaces for database queries or external API calls.
Configuration Module(s): Wiring everything together in runtimes (e.g., Quarkus, Spring Boot, Open Liberty, …)


This clean architecture outline will be used within the parent template project. It will allow external core (i.e., blue) and data providers (i.e., orange) modules to be injected into this union layer to extend it with microservice specific business logic (i.e., code).

The parent’s template code is then injected into the specialists’ Git repository as a Git submodule. This ensures that updates to the parent framework (such as dependency upgrades or security patches) can be propagated across all microservices in a controlled and versioned manner, without disrupting individual services.

However, to ensure the specialists’ code can still compile and function, we need to link both code source locations (i.e., directories) within this repository. In order to do so, I introduce a merge script, which ensures that updates from the parent framework can be pulled into and be linked to this specialists’ repository, while maintaining clear boundaries between stakeholders. It allows that new framework versions are integrated smoothly, without disrupting ongoing development efforts.  This lightweight script integrates the template maintainers’ code into the specialists’ repository by configuring, downloading, and merging updates from the parent framework. This approach keeps the two repositories decoupled in terms of ownership and maintenance, while allowing the specialists’ code to remain functional. Whenever you would decouple the parent repository (e.g., by not using the merge script anymore), the specialists’ repository can remain, which makes that the “independence rule” of microservice architectures isn’t entirely broken by this approach.  

The merge script itself is lightweight and rarely changes. Even if adjustments are needed, they can be automated and applied uniformly across all microservices using the framework. This approach preserves clean architecture principles, maintains stakeholder boundaries, and ensures that updates to shared code can be seamlessly propagated across all dependent repositories.

This approach provides a scalable way to manage shared templates while aligning with clean architecture principles. By keeping the core, API, and data providers separate, teams can maintain flexibility and avoid tight coupling between services and shared dependencies.

In practice
If you want to experiment with this approach, you can use this (parent) GitHub repository. This repository contains the common code maintained by the template maintainers. It's a standalone clean architecture project that compiles and can run independently.

**IMPORTANT PREREQUISITE:**
Before using the bootstrap script, you MUST have a Git repository initialized. The script will FAIL if run in a folder that is not a Git repository. You can either:
1. Create and initialize a new Git repository: `mkdir my-project && cd my-project && git init`
2. Clone an existing repository: `git clone <your-repo-url> && cd <repo-folder>`

Now, imagine you're a specialist looking to create a microservice based on this common framework. To do so, you'll need to:
Create a GitHub repository (i.e., specialists' code base).
Check it out via the command line and 'cd' into it (OR initialize a new Git repository with `git init`).

Add the parent template (i.e., the template maintainers’ common code) to the specialists’ project, by executing the following command: 

bash <(curl -s -H 'Cache-Control: no-cache' https://raw.githubusercontent.com/maarten-vandeperre/software-template-parent_kotlin/refs/heads/main/template-scripts/bootstrap-complete.sh)



When you open the project in IntelliJ (or another editor), you should see a similar project structure as:

Where:
.submodules contains the git submodules.
_submodules contains a work copy of the template, in which you can modify some stuff within custom code blocks (e.g., custom-project-metadata-start, custom-code-start, custom-dependencies-start). On updates from the git modules, these blocks are the only ones that will remain untouched.


You can use it to e.g., change the project’s group name.



The bootstrap script will automatically:
- Initialize the git submodule
- Create the _submodules working directory
- Set up symlinks for gradle files
- Configure the code structure with application modules
- Fix platform and parent-application references in all gradle files
- Add application module dependencies to both Quarkus and OpenLiberty runtime configurations
- Set the root project name

All of these steps are now automated, so you can immediately start developing!





The application folder is the folder where the specialists can put their code and their clean architecture modules.
You can now start the application by running one of the following commands:

For Quarkus (default):
```bash
./gradlew startMonolith
```

For OpenLiberty:
```bash
./gradlew startMonolith -PmonolithRuntime=openliberty
```

The application will be available at:
- Quarkus: http://localhost:8080/maarten-monolith/api/dummy
- OpenLiberty: http://localhost:8080/monolith/api/dummy

Both should return: "No hello, no fooling around: start API development!"


Whenever something changes on the parent template, the code can be updated by running the following command: 

sh script_update_parent_template.sh

You can try this for yourself by forking the parent template repository or by reaching out to me.

TODO: a video of working with the parent template
Application CI/CD: how to enable CI/CD around these components
For now, to keep things simple (and because a good engineer is often a lazy one, as they say), I’ve chosen to add the submodules' working folder (i.e., _submodules) to version control. You might argue that only the parts between the custom blocks (i.e., the deltas) need to be checked in, and I’d completely agree. However, since this is an open-source project, feel free to contribute by adding scripts to enable that functionality. 😉

At this stage, we now have a source code repository that runs independently. From here, you can introduce CI/CD pipelines tailored to your needs. You could integrate them directly into the parent template project, or, for a cleaner separation of concerns, create a dedicated parent template project specifically for CI/CD. This latter approach is something I’ll delve into in one of the upcoming blog posts.
Conclusion
In this post, I explained the value of software templates and addressed the challenge of maintaining them over time. By combining clean architecture principles with a logical repository split and lightweight merge scripts, we achieved modularity, maintainability, and centralized management without compromising microservices independence.

This approach empowers teams to focus on scalable and reliable development while fostering collaboration across stakeholders. Stay tuned for future posts where I’ll delve into CI/CD strategies and their integration into this framework.


